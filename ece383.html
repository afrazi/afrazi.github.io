<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>ECE 383: Introduction to Robotics</title>

    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300i,400" rel="stylesheet">
    <link href='https://fonts.googleapis.com/css?family=Noticia+Text:400,700' rel='stylesheet' type='text/css' />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="icon" href="./static/figures/favicon.ico">
    <link rel="stylesheet" href="./static/css/style.css?20210206H0555" type="text/css" />

    <!-- MathJax for LaTeX formulas -->
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <style>
        a {
            color: darkblue;
        }
        img {
            max-width: 60%;
            display: block;
            margin: 20px auto;
            border: 1px solid #ccc;
            border-radius: 6px;
        }
        .toc a {
            text-decoration: none;
            color: #003f7d;
        }
        .slideshow-container {
            max-width: 600px;
            position: relative;
            margin: auto;
            margin-bottom: 20px;
        }
        .mySlides {
            display: none;
        }
        .mySlides img,
        .mySlides iframe {
            width: 100%;
            height: auto;
            min-height: 340px; /* Adjust as needed */
            border-radius: 8px;
            border: 1px solid #ccc;
        }
        .prev, .next {
            cursor: pointer;
            position: absolute;
            top: 50%;
            width: auto;
            margin-top: -22px;
            padding: 16px;
            color: white;
            font-weight: bold;
            font-size: 18px;
            transition: 0.6s ease;
            border-radius: 0 3px 3px 0;
            user-select: none;
            background-color: rgba(0, 0, 0, 0.5);
        }
        .next {
            right: 0;
            border-radius: 3px 0 0 3px;
        }
        .prev:hover, .next:hover {
            background-color: rgba(0, 0, 0, 0.8);
        }
        .dots-container {
            margin-bottom: 40px;
        }
        .dot {
            cursor: pointer;
            height: 15px;
            width: 15px;
            margin: 0 2px;
            background-color: #bbb;
            border-radius: 50%;
            display: inline-block;
            transition: background-color 0.6s ease;
        }
        .active, .dot:hover {
            background-color: #717171;
        }
        .fade {
            animation-name: fade;
            animation-duration: 0.5s;
        }
        @keyframes fade {
            from { opacity: .4 }
            to { opacity: 1 }
        }
    </style>
</head>

<body>

<div class="container">

    <span class="name"><a href="./index.html"><b>Mohammad Afrazi</b></a></span>
    <div class="navigation">
        <ul>
            <li><a href="./Teaching.html"><b>Teaching</b></a></li>
            <li class="dropdown"><a href="javascript:void(0)" class="dropbtn"><b>Projects</b></a>
                <div class="dropdown-content">
                    <a href="./ece383.html">ECE 383 introduction to robotics</a>
                </div>
            </li>
            <li><a href="./publications.html"><b>Publications</b></a></li>
            <li><a href="./research.html"><b>Research</b></a></li>
            <li><a href="./index.html"><b>Home</b></a></li>
        </ul>
    </div>

    <div class="separator"></div>

    <div class="body">
        <div class="page">
            <h2 style="color:#003f7d; margin-top:10px;">Project Media Album</h2>
            <div class="slideshow-container">
                <div class="mySlides fade">
                    <iframe src="https://www.youtube.com/embed/S4rzMDp9mQ8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </div>
                <div class="mySlides fade">
                    <iframe src="https://www.youtube.com/embed/lEvdTODG6ZE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </div>
                <div class="mySlides fade"><img src="image2.jpeg" alt="Image 2"></div>
                <div class="mySlides fade"><img src="image3.jpeg" alt="Image 3"></div>
                <div class="mySlides fade"><img src="Image4.png" alt="Image 4"></div>
                <div class="mySlides fade"><img src="image1.jpeg" alt="Image 1"></div>

                <a class="prev">&#10094;</a>
                <a class="next">&#10095;</a>
            </div>
            <div class="dots-container" style="text-align:center">
            </div>

            <h1>Final Project: RoboBarista</h1>
            <h3>Gesture-Controlled Pouring System<br>Closed-Loop Sensor Integration with YOLO & Kinova</h3>
            <p><b>Course:</b> ECE 383 â€” Introduction to Robotics<br><b>Team:</b> 5<br><b>Submitted by:</b> Mohammad Afrazi<br><b>Date:</b> Today</p>

            <h2>RoboBarista -- Gesture-Controlled Robotic Pouring</h2>
            <p>RoboBarista is an autonomous, gesture-controlled pouring system built around a Kinova Gen3 Lite robotic arm and a ROS~2 software stack. The goal of the project was to move beyond simple pick-and-place and tackle fluid and granular manipulation, where trajectory shape and timing matter for avoiding spills and achieving consistent, repeatable pours.</p>

            <img src="system_diagram.png" alt="System Diagram">
            <img src="robot_pour.png" alt="Robot Pouring">

            <p>A YOLOv8n-based vision pipeline runs on a live camera feed and detects numerical hand gestures in a designated region of interest. Holding up one finger selects a <em>Simple Gravimetric Pour</em>, while two fingers trigger a <em>Barista-Style Circular Pour</em>. The detector publishes the recognized gesture to a <code>/gesture</code> topic, where a <code>GestureControl</code> supervisor node maps it to the appropriate behavior node. To make the interaction robust, the perception layer includes ROI cropping, confidence thresholds, multi-frame debouncing, and a state-change rule so the robot only reacts to intentional, stable commands. Once a command is accepted, the system enters a <code>BUSY</code> state and ignores further gestures until the motion is complete.</p>
            <p>On the execution side, both behaviors use MoveIt~2 to generate Cartesian paths for the Kinova arm. In the Simple Gravimetric Pour, the robot picks up a custom cup, moves above a bowl, and performs a slow, 20-step tilt between upright and pouring orientations. A digital scale---built from a load cell, amplifier, and Arduino---streams live mass readings over serial to a ROS~2 scale node, which publishes on <code>/weight</code>. The pouring node monitors this topic and stops as soon as the measured mass exceeds 100~g, then returns the cup upright and places it back on the table. In the Barista-Style Circular Pour, the arm tilts the cup once to a fixed angle and then follows a parametric circular trajectory of radius 3~cm above the bowl, computing waypoints using
            \[
            x_i = x_c + r \cos(\theta_i), \qquad
            y_i = y_c + r \sin(\theta_i).
            \]
            This mode runs open loop and focuses on producing a smooth, visually pleasing circular pouring pattern similar to manual barista techniques.</p>
            <p>Under the hood, the system follows a clean Supervisor--Worker architecture. The YOLO node handles perception, <code>GestureControl</code> handles decision-making and concurrency using a <code>MultiThreadedExecutor</code> and background threads, and the two motion ``bots'' (<code>coffee_pourer.py</code> and <code>coffee_pourer_v2.py</code>) encapsulate the gravimetric and circular pouring behaviors. A separate scale node bridges the Arduino-based scale into ROS~2. Together, these components form a full human-robot collaboration pipeline that combines vision, motion planning, and feedback control for dynamic pouring in a human-centric, touchless interface.</p>
            <h3>My Role</h3>
            <p>My contributions to RoboBarista focused on motion control, system integration, and overall robustness of the behavior pipeline. I designed and implemented the motion control pipeline for the Kinova Gen3 Lite using MoveIt~2, including pick-and-place logic from the home pose to the cup and from the cup to the pouring location. I developed the trajectory generation for both pouring modes: a static precision pour with a controlled retract motion once the stop condition is reached, and a barista-style circular pour based on parametric equations that compute Cartesian waypoints on the fly for a smooth circular motion.</p>
            <p>Together with Celia and Feng, I connected and troubleshot the YOLOv8 gesture recognition node and its interface to the robot controller so that discrete gesture labels from <code>/gesture</code> directly trigger the appropriate behavior in the <code>GestureControl</code> supervisor. I also helped design the logic that maps class ``1'' and ``2'' to the Simple Gravimetric Pour and Barista Circular Pour modes, ensuring clean state transitions and preventing accidental re-triggers.</p>
            <p>Together with Alexey, I integrated and troubleshot the Arduino-based digital scale in the robot execution loop by consuming the <code>/weight</code> topic inside the gravimetric pouring behavior. This replaced naive time-based pouring with true closed-loop control, where the robot stops tilting based on real-time weight measurements. I also contributed to redesigning the pouring motion from a single fast 90$^{\circ}$ tilt, which caused overshoot and spills, into a 20-step slow tilt while monitoring weight, significantly reducing overshoot around the 100~g target.</p>
            <p>In addition to these specific contributions, I was responsible for ensuring that the entire RoboBarista system worked end-to-end. I integrated the perception, supervision, and motion layers, connected the Kinova arm, YOLO-based gesture recognition, and Arduino-based scale into a single ROS~2 pipeline, and focused on troubleshooting issues at the interfaces between components. My role was to make sure that everything---from software dependencies and topic wiring to real-time behavior on the robot---was correctly connected and running reliably during our final experiments.</p>
        </div>
    </div>

    <div class="footer">
        <p>&copy; Copyright <script language="JavaScript">var date = new Date(); document.write(date.getFullYear());</script> by Mohammad Afrazi</p>
        <div class="social" style="font-size: 27px;">
            <ul>
                <script language="JavaScript">
                    front = 'mohammad.afrazi';
                    school = 'nmt';
                    tld = 'edu';
                    document.write('<a href=\"mailto:' + front + '@' + school + '.' + tld + '\" target=\"_blank\">');
                </script>
                <li><i class="fa fa-envelope" style="color:darkblue"></i></li>
                <a href="https://github.com/mohammad-afrazi" target="_blank"><li><i class="fa fa-github" style="color:darkblue"></i></li></a>
                <a href="https://scholar.google.com/citations?user=YxXMYTQAAAAJ&hl=en" target="_blank"><li><i class="ai ai-google-scholar" style="color:darkblue"></i></li></a>
                <a href="https://www.linkedin.com/in/mohammad-afrazi/" target="_blank"><li><i class="fa fa-linkedin-square" style="color:darkblue"></i></li></a>
            </ul>
        </div>
    </div>

</div>
<script src="static/js/dropdown.js"></script>
<script src="static/js/slider.js"></script>
</body>
</html>
